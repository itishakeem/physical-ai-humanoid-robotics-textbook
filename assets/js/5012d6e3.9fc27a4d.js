"use strict";(globalThis.webpackChunkmy_book=globalThis.webpackChunkmy_book||[]).push([[9855],{5323:(n,r,e)=>{e.r(r),e.d(r,{assets:()=>l,contentTitle:()=>s,default:()=>m,frontMatter:()=>i,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"chapter6/diagrams","title":"Chapter 6: Motion and Navigation - Diagrams / Illustrations","description":"Path Planning Algorithm Visualization","source":"@site/docs/chapter6/diagrams.md","sourceDirName":"chapter6","slug":"/chapter6/diagrams","permalink":"/docs/chapter6/diagrams","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/chapter6/diagrams.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 6: Motion and Navigation - Practical Examples","permalink":"/docs/chapter6/practical_examples"}}');var o=e(4848),a=e(8453);const i={},s="Chapter 6: Motion and Navigation - Diagrams / Illustrations",l={},c=[{value:"Path Planning Algorithm Visualization",id:"path-planning-algorithm-visualization",level:2},{value:"Gait Generation and Walking Cycle",id:"gait-generation-and-walking-cycle",level:2},{value:"SLAM Process: Building Maps and Localizing",id:"slam-process-building-maps-and-localizing",level:2},{value:"Real-Time Obstacle Avoidance",id:"real-time-obstacle-avoidance",level:2}];function d(n){const r={code:"code",h1:"h1",h2:"h2",header:"header",hr:"hr",p:"p",pre:"pre",...(0,a.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(r.header,{children:(0,o.jsx)(r.h1,{id:"chapter-6-motion-and-navigation---diagrams--illustrations",children:"Chapter 6: Motion and Navigation - Diagrams / Illustrations"})}),"\n",(0,o.jsx)(r.h2,{id:"path-planning-algorithm-visualization",children:"Path Planning Algorithm Visualization"}),"\n",(0,o.jsx)(r.p,{children:"This diagram shows the difference between graph-based and sampling-based planning."}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{children:"GRAPH-BASED PLANNING (Dijkstra, A*)\r\n\r\nEnvironment: 50m \xd7 50m warehouse, 10cm grid\r\n\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 S = Start (left)                   \u2502\r\n\u2502 G = Goal (right)                   \u2502\r\n\u2502 \u2588 = Obstacles (shelves)            \u2502\r\n\u2502 \xb7 = Free space (grid cells)        \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\nEnvironment Map:\r\n  \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  G\r\n  \u2588\xb7\xb7\xb7\xb7\xb7\xb7\xb7\u2588\xb7\xb7\r\n  \u2588\xb7\u2588\u2588\u2588\u2588\u2588\xb7\u2588\xb7\xb7\r\n  \u2588\xb7\u2588   \u2588\xb7\u2588\xb7\xb7\r\n  \u2588\xb7\u2588 S \u2588\xb7\u2588\xb7\xb7\r\n  \u2588\xb7\u2588   \u2588\xb7\u2588\xb7\xb7\r\n  \u2588\xb7\u2588\u2588\u2588\u2588\u2588\xb7\u2588\xb7\xb7\r\n  \u2588\xb7\xb7\xb7\xb7\xb7\xb7\xb7\xb7\u2588\xb7\r\n  \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\xb7\r\n\r\nDijkstra's Algorithm Execution:\r\n  Grid size: 500 \xd7 500 cells = 250,000 nodes\r\n  Edges per node: 4-8 (adjacent cells)\r\n  Algorithm: Expand from start, visiting lowest-cost unvisited nodes\r\n  \r\n  Cost Map (distance from start):\r\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n  \u2502 50 40 30 20 10  G                 \u2502\r\n  \u2502 \u2588 41 42 43 44 \u2588 9  8  7          \u2502\r\n  \u2502 \u2588 40 \u2588 44 45 \u2588 8  \u2588 6            \u2502\r\n  \u2502 \u2588 39 \u2588      \u2588 7  \u2588 5            \u2502\r\n  \u2502 \u2588 38 \u2588  S   \u2588 6  \u2588 4            \u2502\r\n  \u2502 \u2588 37 \u2588      \u2588 5  \u2588 3            \u2502\r\n  \u2502 \u2588 36 \u2588 47 48 \u2588 4  \u2588 2            \u2502\r\n  \u2502 \u2588 35 34 33 32 31 \u2588 1 1            \u2502\r\n  \u2502 \u2588 36 37 38 39 40 \u2588 1 0            \u2502\r\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n  \r\n  Path: S \u2192 (step north around obstacles) \u2192 G\r\n  Path length: 50 steps\r\n  Computation time: ~1 second\r\n  Path quality: Optimal (shortest path)\r\n\r\n\r\nSAMPLING-BASED PLANNING (RRT)\r\n\r\nStart: S\r\nGoal: G\r\nSample count: 3000\r\n\r\nTree Growth (visualization at various iterations):\r\n\r\nIteration 100:\r\n  Tree nodes: 100\r\n  S ----*----* \r\n        \\    \\---* \r\n         \\       \\---* \r\n          \\           * \r\n           *-*-*-* \r\n\r\nIteration 1000:\r\n  Tree nodes: 1000\r\n  More coverage:\r\n  S branches widely\r\n  Many nodes approach G region\r\n  \r\nIteration 2000:\r\n  Tree nodes: 2000\r\n  Some branches reach G region\r\n  \r\nFinal iteration:\r\n  Successfully connected!\r\n  Path: S \u2192 (random walk) \u2192 G\r\n  \r\nSampling trace:\r\n  Sample 1: [30m, 40m] \u2192 too far, ignored\r\n  Sample 2: [20m, 30m] \u2192 connects to tree\r\n  Sample 3: [15m, 25m] \u2192 collision, ignored\r\n  Sample 4: [35m, 35m] \u2192 connects toward goal\r\n  ...\r\n  Sample 2847: [48m, 49m] \u2192 within goal region!\r\n  \r\nFinal path found after 2847 iterations\r\nPath length: 62 steps (not optimal, longer than Dijkstra)\r\nComputation time: ~500 ms (depends on random samples)\r\nPath quality: Good (not optimal but collision-free)\r\n\r\nCOMPARISON:\r\n\r\n                Dijkstra    RRT\r\nOptimality:     Optimal     Suboptimal\r\nTime:           1000 ms     500 ms\r\nHigh-dimension: Poor        Excellent\r\nReal-time:      No          Yes (after planning)\r\nPredictability: Always      Variable\n"})}),"\n",(0,o.jsx)(r.hr,{}),"\n",(0,o.jsx)(r.h2,{id:"gait-generation-and-walking-cycle",children:"Gait Generation and Walking Cycle"}),"\n",(0,o.jsx)(r.p,{children:"This diagram illustrates the walking cycle and how it translates to joint angles."}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{children:"WALKING CYCLE (Duration: ~1 second at normal speed)\r\n\r\nPhase Breakdown (Left-Right Leg Symmetry):\r\n\r\n                      TIMELINE (seconds)\r\n         0.0         0.25        0.5         0.75        1.0\r\n         \u2502           \u2502           \u2502           \u2502           \u2502\r\n  Left   \u251c\u2500 Stance \u2500\u2524 \u251c\u2500 Swing \u2500\u2524 \u251c\u2500 Stance \u2500\u2524 \u251c\u2500 Swing \u2500\u2524\r\n  Leg    \u2502(flat)    \u2502 \u2502 (lift)  \u2502 \u2502(flat)    \u2502 \u2502 (lift)  \u2502\r\n         \u2502          \u2502 \u2502         \u2502 \u2502          \u2502 \u2502         \u2502\r\n  Right  \u251c\u2500 Swing \u2500\u2524 \u251c\u2500 Stance \u2500\u2524 \u251c\u2500 Swing \u2500\u2524 \u251c\u2500 Stance \u2500\u2524\r\n  Leg    \u2502 (lift)  \u2502 \u2502(flat)    \u2502 \u2502 (lift)  \u2502 \u2502(flat)    \u2502\r\n\r\n\r\nJOINT ANGLE TRAJECTORIES OVER WALK CYCLE:\r\n\r\nHip Flexion (degrees)\r\n    20 \u2524     \u2571\u2572\r\n       \u2502    \u2571  \u2572\r\n     0 \u251c\u2500\u2500\u2500\u2571    \u2572\u2500\u2500\u2500\r\n       \u2502 \u2571        \u2572\r\n  -20 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\r\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Time (seconds)\r\n       0  0.25  0.5  0.75  1.0\r\n\r\nKnee Angle (degrees)\r\n    60 \u2524      \u2571\u2572      \u2571\u2572\r\n       \u2502     \u2571  \u2572    \u2571  \u2572\r\n    30 \u251c\u2500\u2500\u2500\u2500\u2571    \u2572\u2500\u2500\u2571    \u2572\r\n       \u2502  \u2571        \u2572      \u2572\r\n     0 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\r\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\r\n       0  0.25  0.5  0.75  1.0\r\n\r\nAnkle Angle (degrees)\r\n    30 \u2524\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\r\n       \u2502      \u2572\u2571      \u2572\u2571\r\n     0 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\r\n       \u2502    \u2571\u2572      \u2571\u2572\r\n  -30 \u251c   \u2571  \u2572\u2500\u2500\u2500\u2500\u2571  \u2572\u2500\u2500\r\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\r\n       0  0.25  0.5  0.75  1.0\r\n\r\nInterpretation:\r\n- Hip flexion increases during swing (leg lifts and moves forward)\r\n- Knee bends during swing (shorten leg for clearance)\r\n- Ankle transitions from plantarflexion (toes point) to dorsiflexion (toe up)\r\n\r\nCenter of Mass (CoM) Trajectory:\r\n\r\nHeight above ground (cm)\r\n    100 \u2524   \u2571\u2572   \u2571\u2572   \u2571\u2572\r\n        \u2502  \u2571  \u2572 \u2571  \u2572 \u2571  \u2572\r\n     95 \u251c\u2500\u2571    \u2572\u2571    \u2572\u2571    \u2572\r\n        \u2502\r\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Time\r\n        0  0.25  0.5  0.75  1.0\r\n\r\nHorizontal position (cm)\r\n    100 \u2524\u2571\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\r\n        \u2502\r\n     50 \u251c\u2500\r\n        \u2502\r\n      0 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\r\n        0  0.25  0.5  0.75  1.0\r\n\r\nPattern: CoM height dips during single-support (unstable; heavier load on one leg)\r\n         CoM height peaks during double-support transition\r\n         Horizontal movement: Smooth, nearly constant velocity\r\n\r\n\r\nZERO MOMENT POINT (ZMP) During Walking:\r\n\r\nDuring double-support phase (both feet on ground):\r\n  \u250c\u2500 Left foot \u2500\u2510     \u250c\u2500 Right foot \u2500\u2510\r\n  L___L___L___L___ZMP___R___R___R___R___R\r\n  \r\n  ZMP can move across foot contact area\r\n  Distance from center: 0-15 cm (safe)\r\n\r\nDuring single-support phase (left foot planted):\r\n  \u250c\u2500\u2500\u2500\u2500\u2500 Left foot \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n  L___L___L___ZMP_L___L___L\r\n  \r\n  ZMP must stay under left foot\r\n  Distance from center: 0-10 cm (high stability requirement)\r\n  Body CoM must be directly above ZMP\r\n  \r\nFailure condition:\r\n  ZMP exits support polygon \u2192 moment develops \u2192 robot tips\r\n\r\nControl strategy to maintain ZMP:\r\n  If ZMP drifts toward toe:\r\n    Angle ankle to reduce toe load\r\n    Shift hip backward\r\n    \r\n  If ZMP drifts toward heel:\r\n    Angle ankle to increase toe load\r\n    Shift hip forward\r\n    \r\nActive feedback at 100 Hz prevents falling\n"})}),"\n",(0,o.jsx)(r.hr,{}),"\n",(0,o.jsx)(r.h2,{id:"slam-process-building-maps-and-localizing",children:"SLAM Process: Building Maps and Localizing"}),"\n",(0,o.jsx)(r.p,{children:"This diagram illustrates how robots build maps while navigating unknown environments."}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{children:"VISUAL SLAM PROCESS (ORB-SLAM)\r\n\r\nStep 1: FEATURE DETECTION\r\n\r\nRaw camera image:\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502              \u2502\r\n\u2502     Wall     \u2502\r\n\u2502              \u2502\r\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2510      \u2502\r\n\u2502  \u2502Door\u2502      \u2502  \u2190 Unique features:\r\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2518      \u2502     Corners, edges, patterns\r\n\u2502   \u25b3 (object) \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\nORB Feature Detection:\r\n     *\r\n    * *                    *\r\n   *   *        \u2192          * *\r\n    * *    Corner         *\r\n     *   detection        * *\r\n        \u2571\u2572 \r\n       \u2571  \u2572   Line\u2192 * * * \r\n      \u2571    \u2572       (grouped as corner)\r\n\r\nDetected features: ~1000 keypoints per image\r\nEach feature has:\r\n  - Position: (x, y) in image\r\n  - Descriptor: 256-bit binary vector (describes local appearance)\r\n  - Orientation: Angle for rotation invariance\r\n\r\n\r\nStep 2: FEATURE TRACKING ACROSS FRAMES\r\n\r\nFrame N-1: \r\n     Feature A (400, 300)\r\n     Feature B (200, 150)\r\n     ...\r\n     \r\nFrame N (0.1 seconds later):\r\n     Feature A (410, 305)  \u2190 Matched to Frame N-1\r\n     Feature B (210, 155)  \u2190 Matched to Frame N-1\r\n     Feature C (500, 200)  \u2190 New feature\r\n     \r\nMotion estimation:\r\n  Feature A displacement: [10, 5] pixels\r\n  Feature B displacement: [10, 5] pixels\r\n  \u2192 Camera moved 10-12 pixels in frame (corresponds to ~0.2m in real world)\r\n\r\n\r\nStep 3: 3D TRIANGULATION\r\n\r\nTwo camera positions (Frame N-1 and Frame N):\r\n  Camera N-1 at position P1\r\n  Camera N at position P2\r\n  Feature A visible in both frames\r\n  \r\nUsing camera intrinsics + feature positions:\r\n  Draw ray from P1 through Feature A pixels\r\n  Draw ray from P2 through Feature A pixels\r\n  Intersection point \u2192 3D world position of Feature A\r\n  \r\nResult: 3D map of Feature A coordinates\r\n\r\n\r\nStep 4: LOOP CLOSURE\r\n\r\nAfter exploring, robot revisits known location:\r\n  \r\n  Map before loop closure:\r\n    [ Keyframe 1 ]\r\n    [ Keyframe 2 ]\r\n    ... (50 keyframes, drifted 1 meter)\r\n    [ Keyframe 50 - position drifted to [5, 5] ]\r\n    \r\n    Detects features from Keyframe 1 again!\r\n    \r\n  Action: Recognize loop closure\r\n    Keyframe 50 matches Keyframe 1\r\n    \u2192 Add constraint: Keyframe 1 \u2248 Keyframe 50\r\n    \r\n  Optimization: Redistribute error\r\n    Previous trajectory:\r\n      [0,0] \u2192 [0.1, 0.1] \u2192 [0.2, 0.3] \u2192 [1.0, 1.5] \r\n      accumulated error\r\n    \r\n    After loop closure:\r\n      [0,0] \u2192 [0.05, 0.05] \u2192 [0.10, 0.15] \u2192 [0.5, 0.75]\r\n      error distributed across entire trajectory\r\n    \r\n  Result: Much more accurate map\r\n\r\n\r\nCOMPUTATIONAL COST:\r\n\r\nImage processing: 33 ms per frame (30 fps)\r\nFeature detection: 10 ms\r\nFeature matching: 5 ms\r\nMotion estimation: 3 ms\r\nTriangulation: 5 ms\r\nMap optimization: 10 ms (every 10 frames)\r\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\r\nTotal: ~33 ms \u2192 real-time capable\r\n\r\n\r\nLIDAR SLAM (Scan Matching):\r\n\r\nLiDAR scan: 64 laser beams, 10 Hz scan rate\r\nPoint cloud: 64,000 points per scan (vertical scan)\r\n\r\nScan N-1: Points from location [0, 0]\r\nScan N: Points from location [0.3, 0]  (robot moved forward)\r\n\r\nICP (Iterative Closest Point):\r\n  1. Find nearest point in Scan N for each point in Scan N-1\r\n  2. Compute optimal transformation (rotation + translation)\r\n  3. Apply transformation\r\n  4. Repeat until convergence (usually 10-20 iterations)\r\n  \r\nResult: Transformation = [0.3, 0] (robot moved 0.3m forward)\r\n\r\nScan matching accuracy: 0.05-0.2m per scan\r\nBetter than visual SLAM: More robust to lighting, texture\r\nMore expensive: Requires more computation\r\n\r\nScan storage: \r\n  Each scan: ~1 MB (point cloud data)\r\n  1 hour warehouse mapping: 36,000 scans = 36 GB\r\n  Compression: 1-2 GB (after compression)\n"})}),"\n",(0,o.jsx)(r.hr,{}),"\n",(0,o.jsx)(r.h2,{id:"real-time-obstacle-avoidance",children:"Real-Time Obstacle Avoidance"}),"\n",(0,o.jsx)(r.p,{children:"This diagram shows how robots avoid obstacles dynamically."}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{children:"DYNAMIC WINDOW APPROACH (DWA)\r\n\r\nHumanoid robot receives goal: Navigate forward 10 meters\r\nCurrent position: [0, 0]\r\nCurrent velocity: [0.5 m/s, 0\xb0]\r\nObstacle detected: 2 meters ahead, at angle 0\xb0\r\n\r\nStep 1: GENERATE CANDIDATE MOTIONS\r\n\r\nVelocity space (discretized):\r\n  v (forward): 0.0, 0.1, 0.2, ..., 1.5 m/s     (16 options)\r\n  \u03c9 (rotation): -0.5, -0.4, ..., 0.0, ..., 0.5 rad/s (11 options)\r\n  Total: 16 \xd7 11 = 176 candidate motions\r\n\r\nExample candidates:\r\n  1. v=0.0 m/s, \u03c9=0.0 rad/s (stop)\r\n  2. v=0.5 m/s, \u03c9=0.0 rad/s (straight forward)\r\n  3. v=0.3 m/s, \u03c9=0.1 rad/s (slight left turn)\r\n  4. v=0.3 m/s, \u03c9=-0.1 rad/s (slight right turn)\r\n  ...\r\n\r\n\r\nStep 2: SIMULATE EACH MOTION\r\n\r\nFor motion #2 (v=0.5 m/s, \u03c9=0.0\xb0):\r\n  \u250c\u2500\u2500\u2500\u2500 Simulation 1 second ahead \u2500\u2500\u2500\u2500\u2510\r\n  \u2502 t=0.0s:  Position [0, 0]           \u2502\r\n  \u2502 t=0.2s:  Position [0.1, 0]         \u2502\r\n  \u2502 t=0.4s:  Position [0.2, 0]         \u2502\r\n  \u2502 t=0.6s:  Position [0.3, 0]         \u2502 \u2190 Would hit obstacle!\r\n  \u2502 t=0.8s:  Position [0.4, 0]         \u2502\r\n  \u2502 t=1.0s:  Position [0.5, 0]         \u2502\r\n  \u2502                                    \u2502\r\n  \u2502 Obstacle location: [2.0, 0]        \u2502\r\n  \u2502 Collision? YES at t=0.4s           \u2502\r\n  \u2502 Cost: \u221e (unsafe, reject)           \u2502\r\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\nFor motion #4 (v=0.3 m/s, \u03c9=-0.1 rad/s, slight right turn):\r\n  \u250c\u2500\u2500\u2500\u2500 Simulation 1 second ahead \u2500\u2500\u2500\u2500\u2510\r\n  \u2502 t=0.0s:  Position [0.0,  0.0]     \u2502\r\n  \u2502 t=0.2s:  Position [0.06, -0.01]   \u2502\r\n  \u2502 t=0.4s:  Position [0.12, -0.04]   \u2502\r\n  \u2502 t=0.6s:  Position [0.18, -0.09]   \u2502 \u2190 Clears obstacle!\r\n  \u2502 t=0.8s:  Position [0.24, -0.16]   \u2502\r\n  \u2502 t=1.0s:  Position [0.30, -0.25]   \u2502\r\n  \u2502                                    \u2502\r\n  \u2502 Minimum distance to obstacle: 1.8m \u2502\r\n  \u2502 Collision? NO                      \u2502\r\n  \u2502 Cost: 5 (low cost - safe)          \u2502\r\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n\r\nStep 3: SCORE EACH VALID MOTION\r\n\r\nCost function combines multiple objectives:\r\n\r\nCost = \u03b1\xb7(distance_to_goal_error) \r\n     + \u03b2\xb7(min_distance_to_obstacle)\r\n     + \u03b3\xb7(smoothness_deviation)\r\n     + \u03b4\xb7(speed_deviation)\r\n\r\nFor motion #4 (right turn):\r\n  Distance to goal error: 9.7m (moved 0.3m toward 10m goal)\r\n    Contribution: 0.3 \xd7 9.7 = 2.9\r\n\r\n  Min distance to obstacle: 1.8m (safe)\r\n    Contribution: -0.1 \xd7 1.8 = -0.18 (negative for safety)\r\n  \r\n  Smoothness: Changed \u03c9 by 0.1 rad/s (small)\r\n    Contribution: 0.05 \xd7 0.01 = 0.0005\r\n\r\n  Speed deviation: 0.3 m/s (target 0.5)\r\n    Contribution: 0.2 \xd7 0.04 = 0.008\r\n\r\n  Total cost: 2.9 - 0.18 + 0.0005 + 0.008 \u2248 2.73\r\n\r\n\r\nStep 4: SELECT BEST MOTION\r\n\r\nEvaluate all 176 motions:\r\n  Motion 1: Cost = \u221e (collision)\r\n  Motion 2: Cost = \u221e (collision)\r\n  Motion 3: Cost = 2.81\r\n  Motion 4: Cost = 2.73 \u2190 BEST\r\n  Motion 5: Cost = 2.85\r\n  ...\r\n  Motion 176: Cost = 5.2\r\n\r\nSelect motion #4: v=0.3 m/s, \u03c9=-0.1 rad/s (gentle right turn)\r\n\r\n\r\nStep 5: EXECUTE AND REPEAT\r\n\r\nSend command: v=0.3 m/s, \u03c9=-0.1 rad/s to motion controller\r\nWheels rotate accordingly\r\nRobot steers gently right while moving forward\r\n100 ms later: New sensor reading, new obstacle position\r\nRe-run DWA (next iteration)\r\n\r\nResult: Smooth, adaptive navigation around obstacle\r\nRobot continuously updates motion based on new sensor data\r\n\r\n\r\nPERFORMANCE COMPARISON:\r\n\r\nMethod          Time/decision  Smoothness  Reactivity\r\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\r\nVector Field    &lt;5 ms          Low         Excellent\r\n(VFH)           Too fast!      Jerky       Immediate\r\n\r\nPotential       &lt;1 ms          Excellent   Sluggish\r\nFields          Too simple     Smooth      Delayed\r\n\r\nDynamic         50 ms          Good        Good\r\nWindow          Moderate       Smooth      Responsive\r\n\r\nA*+Planning     1000 ms        Excellent   Poor\r\n                Expensive      Very smooth Delayed\n"})})]})}function m(n={}){const{wrapper:r}={...(0,a.R)(),...n.components};return r?(0,o.jsx)(r,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}},8453:(n,r,e)=>{e.d(r,{R:()=>i,x:()=>s});var t=e(6540);const o={},a=t.createContext(o);function i(n){const r=t.useContext(a);return t.useMemo(function(){return"function"==typeof n?n(r):{...r,...n}},[r,n])}function s(n){let r;return r=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:i(n.components),t.createElement(a.Provider,{value:r},n.children)}}}]);