"use strict";(globalThis.webpackChunkmy_book=globalThis.webpackChunkmy_book||[]).push([[7970],{5340:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"chapter3/practical_examples","title":"Chapter 3: Sensors and Actuators - Practical Examples","description":"Environment Mapping with Visual Sensors","source":"@site/docs/chapter3/practical_examples.md","sourceDirName":"chapter3","slug":"/chapter3/practical_examples","permalink":"/docs/chapter3/practical_examples","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/chapter3/practical_examples.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: Sensors and Actuators - Key Concepts","permalink":"/docs/chapter3/key_concepts"},"next":{"title":"Chapter 3: Sensors and Actuators - Diagrams / Illustrations","permalink":"/docs/chapter3/diagrams"}}');var r=i(4848),o=i(8453);const t={},l="Chapter 3: Sensors and Actuators - Practical Examples",a={},c=[{value:"Environment Mapping with Visual Sensors",id:"environment-mapping-with-visual-sensors",level:2},{value:"LiDAR for Indoor Navigation",id:"lidar-for-indoor-navigation",level:3},{value:"Depth Cameras for Close-Range Perception",id:"depth-cameras-for-close-range-perception",level:3},{value:"Multi-Camera Fusion in Tesla Humanoid (Optimus)",id:"multi-camera-fusion-in-tesla-humanoid-optimus",level:3},{value:"Tactile Sensing for Dexterous Manipulation",id:"tactile-sensing-for-dexterous-manipulation",level:2},{value:"Force Control in Robotic Surgery",id:"force-control-in-robotic-surgery",level:3},{value:"Slip Detection in Mobile Manipulation",id:"slip-detection-in-mobile-manipulation",level:3},{value:"Soft Touch in Collaborative Robots",id:"soft-touch-in-collaborative-robots",level:3},{value:"Actuator Performance in Dynamic Tasks",id:"actuator-performance-in-dynamic-tasks",level:2},{value:"Hydraulic Power in Boston Dynamics Atlas",id:"hydraulic-power-in-boston-dynamics-atlas",level:3},{value:"Series Elastic Actuators in Rethink Robotics Baxter",id:"series-elastic-actuators-in-rethink-robotics-baxter",level:3},{value:"Integrated Sensor-Actuator Systems",id:"integrated-sensor-actuator-systems",level:2},{value:"Mobile Manipulation in Mobile Bases with Arm",id:"mobile-manipulation-in-mobile-bases-with-arm",level:3},{value:"Vision-Based Manipulation in KUKA LBR iiwa",id:"vision-based-manipulation-in-kuka-lbr-iiwa",level:3},{value:"Sensor Failure and Redundancy",id:"sensor-failure-and-redundancy",level:2},{value:"Handling Sensor Degradation in Atlas",id:"handling-sensor-degradation-in-atlas",level:3},{value:"Multi-Sensor Fusion in Autonomous Vehicles",id:"multi-sensor-fusion-in-autonomous-vehicles",level:3}];function d(e){const n={h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"chapter-3-sensors-and-actuators---practical-examples",children:"Chapter 3: Sensors and Actuators - Practical Examples"})}),"\n",(0,r.jsx)(n.h2,{id:"environment-mapping-with-visual-sensors",children:"Environment Mapping with Visual Sensors"}),"\n",(0,r.jsx)(n.h3,{id:"lidar-for-indoor-navigation",children:"LiDAR for Indoor Navigation"}),"\n",(0,r.jsx)(n.p,{children:"Boston Dynamics Atlas uses a spinning LiDAR unit to map its environment:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sensor"}),": 32-channel LiDAR scanning at 10Hz, providing 360-degree awareness"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Processing"}),": Raw point cloud processed to identify walkable surfaces, obstacles, and terrain height variations"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Application"}),": Enables autonomous navigation through warehouses, construction sites, and unstructured environments"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Advantage"}),": Works in various lighting conditions; provides metric distance measurements"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Limitation"}),": Cannot detect transparent objects or distinguish material properties"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"depth-cameras-for-close-range-perception",children:"Depth Cameras for Close-Range Perception"}),"\n",(0,r.jsx)(n.p,{children:"Social humanoid robot Sophia uses RGB-D (depth) cameras:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sensor Configuration"}),": Two RGB-D cameras for stereo vision (closer to human vision)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Use Cases"}),": Face recognition at ~1m range, gesture recognition, object identification"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Advantage"}),": Lower cost than LiDAR, good for fine-grained details"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Limitation"}),": Limited range (~5m), struggles outdoors with infrared interference"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"multi-camera-fusion-in-tesla-humanoid-optimus",children:"Multi-Camera Fusion in Tesla Humanoid (Optimus)"}),"\n",(0,r.jsx)(n.p,{children:"Tesla's proposed humanoid robot plans multi-camera perception:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sensor Suite"}),": 8 cameras with different focal lengths for comprehensive coverage"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Integration"}),": Feeds into neural network for real-time object detection"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Advantage"}),": Redundancy; different focal lengths cover near and far objects"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Challenge"}),": High computational load for processing multiple video streams simultaneously"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"tactile-sensing-for-dexterous-manipulation",children:"Tactile Sensing for Dexterous Manipulation"}),"\n",(0,r.jsx)(n.h3,{id:"force-control-in-robotic-surgery",children:"Force Control in Robotic Surgery"}),"\n",(0,r.jsx)(n.p,{children:"Intuitive Surgical's da Vinci surgical system employs force-feedback:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sensors"}),": Force/torque sensors at instrument tip detect resistance during tissue manipulation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Feedback"}),": Surgeon receives haptic feedback about tissue resistance"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Precision"}),": Forces measured to ~0.1N, enabling delicate manipulation without tearing tissue"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Impact"}),": Enables minimally invasive surgery with reduced patient trauma"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"slip-detection-in-mobile-manipulation",children:"Slip Detection in Mobile Manipulation"}),"\n",(0,r.jsx)(n.p,{children:"Mobile manipulators like FETCH Robotics use slip sensors in grippers:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sensors"}),": Micro-motion sensors detect when objects begin slipping"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Control Algorithm"}),": When slip detected, gripper increases pressure or re-adjusts grip"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Advantage"}),": Prevents object drops without crushing fragile items"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Real-World Use"}),": Picking items from shelves in warehouses without damage"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"soft-touch-in-collaborative-robots",children:"Soft Touch in Collaborative Robots"}),"\n",(0,r.jsx)(n.p,{children:"Universal Robots' collaborative arm (UR10) uses wrist-mounted force/torque sensors:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sensor Data"}),": Continuously monitors interaction forces with humans"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Safety Response"}),": Detects unexpected collisions (force spikes) and stops within milliseconds"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Compliance"}),": Allows teach-by-demonstration where humans can guide the arm"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Certification"}),": Force-limited motion certified safe for human-robot collaboration per ISO/TS 15066"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"actuator-performance-in-dynamic-tasks",children:"Actuator Performance in Dynamic Tasks"}),"\n",(0,r.jsx)(n.h3,{id:"hydraulic-power-in-boston-dynamics-atlas",children:"Hydraulic Power in Boston Dynamics Atlas"}),"\n",(0,r.jsx)(n.p,{children:"Atlas leverages hydraulic actuation for dynamic mobility:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Actuators"}),": Hydraulic cylinders in all joints; hydraulic pump driven by electric motor"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Performance"}),": Enables backflips, explosive jumps, and recovery from falls"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Power Density"}),": Hydraulics deliver 5-10\xd7 the power per unit weight compared to electric motors"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Challenge"}),": Fluid leaks are environmental hazard; complex system with many failure points"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Maintenance"}),": Requires filter changes and fluid inspection"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Example Maneuver"}),": Atlas performing a backflip"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Hydraulic legs compress rapidly, storing energy"}),"\n",(0,r.jsx)(n.li,{children:"Lower body actuators fire in sequence to generate upward momentum"}),"\n",(0,r.jsx)(n.li,{children:"Upper body rotates to control rotation"}),"\n",(0,r.jsx)(n.li,{children:"Landing requires precise ankle and knee control to absorb impact"}),"\n",(0,r.jsx)(n.li,{children:"Entire sequence: ~0.5 seconds"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"series-elastic-actuators-in-rethink-robotics-baxter",children:"Series Elastic Actuators in Rethink Robotics Baxter"}),"\n",(0,r.jsx)(n.p,{children:"Baxter arm uses Series Elastic Actuators for safe human-robot interaction:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Design"}),": Spring between motor and end-effector; force sensor measures spring compression"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Benefits"}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Compliant movement (won't injure humans on contact)"}),"\n",(0,r.jsx)(n.li,{children:"Accurate force control for delicate tasks"}),"\n",(0,r.jsx)(n.li,{children:"Force feedback enables learning from demonstration"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Performance Tradeoff"}),": Lower response speed (~50Hz control vs 1000Hz for stiff actuators)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Application"}),": Manufacturing assembly with human oversight"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"integrated-sensor-actuator-systems",children:"Integrated Sensor-Actuator Systems"}),"\n",(0,r.jsx)(n.h3,{id:"mobile-manipulation-in-mobile-bases-with-arm",children:"Mobile Manipulation in Mobile Bases with Arm"}),"\n",(0,r.jsx)(n.p,{children:"Example: Fetch Mobile Manipulator in warehouse automation"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Locomotion Sensors"}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"LiDAR for obstacle avoidance during navigation"}),"\n",(0,r.jsx)(n.li,{children:"Wheel encoders for odometry tracking"}),"\n",(0,r.jsx)(n.li,{children:"Bumpers for collision detection"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Manipulation Sensors"}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Joint encoders on arm for positioning"}),"\n",(0,r.jsx)(n.li,{children:"Gripper force sensor for object detection and secure grasp"}),"\n",(0,r.jsx)(n.li,{children:"RGB-D camera for object localization"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Integration Challenge"}),": Coordinating multiple control loops:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Navigation loop (10Hz): Plan path avoiding obstacles"}),"\n",(0,r.jsx)(n.li,{children:"Arm motion loop (100Hz): Move arm to manipulate objects"}),"\n",(0,r.jsx)(n.li,{children:"Gripper force loop (1000Hz): Adjust grip to prevent slip"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Real-World Scenario"}),": Pick item from shelf","\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Navigate to shelf using LiDAR-based SLAM"}),"\n",(0,r.jsx)(n.li,{children:"Recognize item using RGB-D camera"}),"\n",(0,r.jsx)(n.li,{children:"Move arm to reach item (joint encoder feedback)"}),"\n",(0,r.jsx)(n.li,{children:"Close gripper until force sensor detects item (50-100N)"}),"\n",(0,r.jsx)(n.li,{children:"Lift with controlled acceleration"}),"\n",(0,r.jsx)(n.li,{children:"Navigate to delivery location"}),"\n",(0,r.jsx)(n.li,{children:"Gently release item"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"vision-based-manipulation-in-kuka-lbr-iiwa",children:"Vision-Based Manipulation in KUKA LBR iiwa"}),"\n",(0,r.jsx)(n.p,{children:"KUKA's sensitive lightweight robot combines advanced sensing and control:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sensors"}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"7 joint torque sensors (extremely sensitive)"}),"\n",(0,r.jsx)(n.li,{children:"Wrist-mounted force/torque sensor"}),"\n",(0,r.jsx)(n.li,{children:"3D camera for object recognition"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Control Strategy"}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Torque feedback enables detection of contact with ~100mN sensitivity"}),"\n",(0,r.jsx)(n.li,{children:"Can detect when placing object on surface (force rises gradually)"}),"\n",(0,r.jsx)(n.li,{children:"Enables tasks like egg cracking (apply controlled force without crushing)"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Application"}),": Delicate assembly, contact-rich manipulation"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"sensor-failure-and-redundancy",children:"Sensor Failure and Redundancy"}),"\n",(0,r.jsx)(n.h3,{id:"handling-sensor-degradation-in-atlas",children:"Handling Sensor Degradation in Atlas"}),"\n",(0,r.jsx)(n.p,{children:"Boston Dynamics Atlas incorporates redundancy:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"LiDAR Failure"}),": Backup stereo cameras can provide environment estimates"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Joint Encoder Failure"}),": Can estimate joint angle from motor current and commanded torque"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"IMU Failure"}),": Fuse remaining accelerometers and gyroscopes from other units"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Graceful Degradation"}),": Robot continues operating at reduced capability rather than immediate shutdown"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"multi-sensor-fusion-in-autonomous-vehicles",children:"Multi-Sensor Fusion in Autonomous Vehicles"}),"\n",(0,r.jsx)(n.p,{children:"Self-driving cars employ redundant sensor suites:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Primary"}),": LiDAR for 3D mapping"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Secondary"}),": Radar for velocity estimation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Tertiary"}),": Stereo cameras for object classification"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Advantage"}),": If one sensor fails, vehicle has fallback perception"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Example"}),": Waymo vehicles continue operating with 2 of 3 primary sensors failed"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"These practical examples illustrate how sensor-actuator selection and integration directly determine robot capability and reliability in real-world tasks."})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>l});var s=i(6540);const r={},o=s.createContext(r);function t(e){const n=s.useContext(o);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);