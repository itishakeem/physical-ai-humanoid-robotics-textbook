"use strict";(globalThis.webpackChunkmy_book=globalThis.webpackChunkmy_book||[]).push([[5624],{8269:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>a,contentTitle:()=>t,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"chapter5/key_concepts","title":"Chapter 5: AI Integration in Humanoids - Key Concepts","description":"Perception: Computer Vision and Sensor Fusion","source":"@site/docs/chapter5/key_concepts.md","sourceDirName":"chapter5","slug":"/chapter5/key_concepts","permalink":"/physical-ai-humanoid-robotics-textbook/docs/chapter5/key_concepts","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/chapter5/key_concepts.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 5: AI Integration in Humanoids","permalink":"/physical-ai-humanoid-robotics-textbook/docs/chapter5/summary"},"next":{"title":"Chapter 5: AI Integration in Humanoids - Practical Examples","permalink":"/physical-ai-humanoid-robotics-textbook/docs/chapter5/practical_examples"}}');var r=i(4848),l=i(8453);const o={},t="Chapter 5: AI Integration in Humanoids - Key Concepts",a={},c=[{value:"Perception: Computer Vision and Sensor Fusion",id:"perception-computer-vision-and-sensor-fusion",level:2},{value:"Convolutional Neural Networks (CNNs) for Vision",id:"convolutional-neural-networks-cnns-for-vision",level:3},{value:"Reinforcement Learning for Skill Acquisition",id:"reinforcement-learning-for-skill-acquisition",level:3},{value:"Natural Language Understanding",id:"natural-language-understanding",level:2},{value:"Speech Recognition Pipeline",id:"speech-recognition-pipeline",level:3},{value:"Vision-Language Models",id:"vision-language-models",level:3},{value:"Autonomous Navigation and Mapping",id:"autonomous-navigation-and-mapping",level:2},{value:"SLAM (Simultaneous Localization and Mapping)",id:"slam-simultaneous-localization-and-mapping",level:3},{value:"Path Planning",id:"path-planning",level:3},{value:"Grasping and Manipulation with Learning",id:"grasping-and-manipulation-with-learning",level:2},{value:"Learning Grasp Prediction",id:"learning-grasp-prediction",level:3},{value:"Dexterous Manipulation",id:"dexterous-manipulation",level:3},{value:"Predictive Models and Planning",id:"predictive-models-and-planning",level:2},{value:"World Models",id:"world-models",level:3},{value:"Integration: Putting It All Together",id:"integration-putting-it-all-together",level:2},{value:"Complete Perception-Cognition-Action Loop",id:"complete-perception-cognition-action-loop",level:3}];function d(n){const e={em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,l.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"chapter-5-ai-integration-in-humanoids---key-concepts",children:"Chapter 5: AI Integration in Humanoids - Key Concepts"})}),"\n",(0,r.jsx)(e.h2,{id:"perception-computer-vision-and-sensor-fusion",children:"Perception: Computer Vision and Sensor Fusion"}),"\n",(0,r.jsx)(e.h3,{id:"convolutional-neural-networks-cnns-for-vision",children:"Convolutional Neural Networks (CNNs) for Vision"}),"\n",(0,r.jsx)(e.p,{children:"CNNs have revolutionized robot perception by enabling robust visual understanding:"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Architecture"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Input Layer"}),": Raw image (e.g., 640\xd7480 RGB = 3 channels)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Convolutional Layers"}),": Learn hierarchical features","\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Layer 1: Edges and corners (simple features)"}),"\n",(0,r.jsx)(e.li,{children:"Layer 2: Textures and shapes (medium complexity)"}),"\n",(0,r.jsx)(e.li,{children:"Layer 3: Object parts (high complexity)"}),"\n",(0,r.jsx)(e.li,{children:"Layer 4: Full objects (semantic level)"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Pooling Layers"}),": Reduce computational load while preserving important features"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Fully Connected Layers"}),": Produce final classification or detection outputs"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Common Architectures"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"ResNet-50"}),": Good balance of accuracy and speed; ~50 ms inference on GPU"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"YOLOv8"}),": Real-time object detection; 30-50 fps on robot hardware"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"SegFormer"}),": Semantic segmentation for scene understanding"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"reinforcement-learning-for-skill-acquisition",children:"Reinforcement Learning for Skill Acquisition"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Policy Gradient Methods"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"TRPO (Trust Region Policy Optimization): Guaranteed monotonic improvement"}),"\n",(0,r.jsx)(e.li,{children:"PPO (Proximal Policy Optimization): Simpler, faster, most popular for robotics"}),"\n",(0,r.jsx)(e.li,{children:"Actor-Critic: Efficient learning using both policy and value networks"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Hierarchical RL"}),": Multi-level policies for long-horizon tasks"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"High-level: Task selection (1 Hz)"}),"\n",(0,r.jsx)(e.li,{children:"Mid-level: Sub-task execution (10 Hz)"}),"\n",(0,r.jsx)(e.li,{children:"Low-level: Motor control (100-1000 Hz)"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Key Challenge"}),": Sim-to-Real Transfer"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Domain randomization: Train on multiple environment variations"}),"\n",(0,r.jsx)(e.li,{children:"System identification: Match simulator to real robot parameters"}),"\n",(0,r.jsx)(e.li,{children:"Online adaptation: Adjust policy based on real robot feedback"}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"natural-language-understanding",children:"Natural Language Understanding"}),"\n",(0,r.jsx)(e.h3,{id:"speech-recognition-pipeline",children:"Speech Recognition Pipeline"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Audio Capture"}),": Microphone array records speech"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Speech Recognition"}),": Convert audio to text (Whisper, etc.)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Natural Language Understanding"}),": Extract intent and parameters"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Task Execution"}),": Convert intent to robot actions"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Response Generation"}),": Generate natural language response"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"vision-language-models",children:"Vision-Language Models"}),"\n",(0,r.jsx)(e.p,{children:"Recent advances enable robots to understand scenes with natural language:"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"CLIP (Contrastive Language-Image Pre-training)"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Learns joint embedding space for images and text"}),"\n",(0,r.jsx)(e.li,{children:"Can match image content with text descriptions"}),"\n",(0,r.jsx)(e.li,{children:"Application: Understand human instructions referring to visual scenes"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Example"}),': Human says "Hand me the blue cup near the window"']}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"CLIP encodes image: Detects all objects (cups, windows, etc.)"}),"\n",(0,r.jsx)(e.li,{children:'CLIP encodes text: Matches "blue cup" to objects'}),"\n",(0,r.jsx)(e.li,{children:'Spatial reasoning: Identifies cup "near window"'}),"\n",(0,r.jsx)(e.li,{children:"Robot locates, grasps, and delivers cup"}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"autonomous-navigation-and-mapping",children:"Autonomous Navigation and Mapping"}),"\n",(0,r.jsx)(e.h3,{id:"slam-simultaneous-localization-and-mapping",children:"SLAM (Simultaneous Localization and Mapping)"}),"\n",(0,r.jsx)(e.p,{children:"SLAM algorithms enable robots to explore unknown environments:"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Process"}),":"]}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Robot explores environment with sensors"}),"\n",(0,r.jsx)(e.li,{children:"Detects features (corners, patterns) in sensor data"}),"\n",(0,r.jsx)(e.li,{children:"Associates features with previous observations"}),"\n",(0,r.jsx)(e.li,{children:"Estimates robot position from feature correspondences"}),"\n",(0,r.jsx)(e.li,{children:"Builds 3D map as robot moves"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Algorithms"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"ORB-SLAM"}),": Fast visual SLAM using feature matching"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"LiDAR-SLAM"}),": High-accuracy using laser scan matching"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Graph-Based SLAM"}),": Optimizes entire trajectory retroactively"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Application"}),": Humanoid navigating office building"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Enters new floor with map"}),"\n",(0,r.jsx)(e.li,{children:"Explores corridors, detecting walls and doorways"}),"\n",(0,r.jsx)(e.li,{children:"Simultaneously estimates position and builds map"}),"\n",(0,r.jsx)(e.li,{children:"After exploration, knows optimal routes between locations"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"path-planning",children:"Path Planning"}),"\n",(0,r.jsx)(e.p,{children:"Once environment is mapped, path planning computes safe navigation:"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Dijkstra's Algorithm"}),": Finds shortest path in graph"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Nodes: Grid positions or waypoints"}),"\n",(0,r.jsx)(e.li,{children:"Edges: Collision-free paths between adjacent positions"}),"\n",(0,r.jsx)(e.li,{children:"Computation: ~1 ms for typical indoor environment"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"RRT (Rapidly-Exploring Random Trees)"}),": Sample-based planner for high dimensions"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Randomly samples configuration space"}),"\n",(0,r.jsx)(e.li,{children:"Connects samples if collision-free"}),"\n",(0,r.jsx)(e.li,{children:"Very fast for high-dimensional problems (e.g., humanoid + arm)"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsxs)(e.em,{children:[(0,r.jsx)(e.em,{children:"D"})," Lite"]}),"*: Dynamic planning for replanning with cost updates"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Initial plan computed"}),"\n",(0,r.jsx)(e.li,{children:"If obstacle detected, locally recomputes affected portions"}),"\n",(0,r.jsx)(e.li,{children:"Much faster than recomputing entire plan"}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"grasping-and-manipulation-with-learning",children:"Grasping and Manipulation with Learning"}),"\n",(0,r.jsx)(e.h3,{id:"learning-grasp-prediction",children:"Learning Grasp Prediction"}),"\n",(0,r.jsx)(e.p,{children:"Modern robots learn to grasp objects from images:"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Grasp Quality Metric"}),": Predicts probability of successful grasp given gripper position/orientation"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Input: RGB-D image + gripper position/approach vector"}),"\n",(0,r.jsx)(e.li,{children:"CNN processes image: Detects object boundaries"}),"\n",(0,r.jsx)(e.li,{children:"Predicts: Likelihood of stable grasp at each gripper position"}),"\n",(0,r.jsx)(e.li,{children:"Output: Grasp pose with highest predicted quality"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Training Data"}),": Collected through:"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Physical exploration: Robot tries 10,000 grasps, tracks successes"}),"\n",(0,r.jsx)(e.li,{children:"Simulation: Physics simulator generates synthetic grasp data"}),"\n",(0,r.jsx)(e.li,{children:"Transfer learning: Pre-train on large dataset, fine-tune on robot"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Real-World Application"}),": Pick-and-place in warehouse"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Robot observes bin of mixed objects"}),"\n",(0,r.jsx)(e.li,{children:"For each object, predicts best grasp from image"}),"\n",(0,r.jsx)(e.li,{children:"Grasp prediction: 10-50 ms"}),"\n",(0,r.jsx)(e.li,{children:"Success rate: 90-95% (compared to 60% for classical methods)"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"dexterous-manipulation",children:"Dexterous Manipulation"}),"\n",(0,r.jsx)(e.p,{children:"Learning to manipulate objects with multi-fingered hands:"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Challenge"}),": High-dimensional control (20+ degrees of freedom in hand)"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Approach"}),": Reinforcement learning in simulation, transfer to real robot"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Example"}),": Learning to rotate cube in-hand"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Simulator: Physics model of hand and cube"}),"\n",(0,r.jsx)(e.li,{children:"Reward: Penalty for each step, bonus for reaching target rotation"}),"\n",(0,r.jsx)(e.li,{children:"Training: 1-10 million simulation steps (hours of GPU time)"}),"\n",(0,r.jsx)(e.li,{children:"Result: Policy that rotates cube using fingertip pushing"}),"\n",(0,r.jsx)(e.li,{children:"Transfer: Domain randomization ensures learned skill works on real robot"}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"predictive-models-and-planning",children:"Predictive Models and Planning"}),"\n",(0,r.jsx)(e.h3,{id:"world-models",children:"World Models"}),"\n",(0,r.jsx)(e.p,{children:"Some advanced systems learn predictive models of environment dynamics:"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Process"}),":"]}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Collect experience: Robot performs random actions, observes results"}),"\n",(0,r.jsx)(e.li,{children:"Train model: Neural network learns to predict: next_state = f(state, action)"}),"\n",(0,r.jsx)(e.li,{children:"Planning: Use model to simulate potential actions"}),"\n",(0,r.jsx)(e.li,{children:"Execution: Execute best predicted action"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Advantage"}),": Can plan without physical execution (faster, safer)"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Challenge"}),": Prediction errors accumulate over long horizons"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Application"}),": Humanoid reaching in new environment"]}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Look at target location"}),"\n",(0,r.jsx)(e.li,{children:"Imagine reaching trajectories using learned dynamics model"}),"\n",(0,r.jsx)(e.li,{children:"Select trajectory with highest predicted success"}),"\n",(0,r.jsx)(e.li,{children:"Execute trajectory"}),"\n",(0,r.jsx)(e.li,{children:"Observe actual result"}),"\n",(0,r.jsx)(e.li,{children:"Update model with new data"}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"integration-putting-it-all-together",children:"Integration: Putting It All Together"}),"\n",(0,r.jsx)(e.h3,{id:"complete-perception-cognition-action-loop",children:"Complete Perception-Cognition-Action Loop"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Scenario"}),': "Bring me a red cup from the shelf"']}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Perception"})," (0-100 ms):"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Vision system: Detect objects on shelf"}),"\n",(0,r.jsx)(e.li,{children:"CNN: Classify objects \u2192 identify red cup"}),"\n",(0,r.jsx)(e.li,{children:"Depth camera: Estimate 3D location of cup"}),"\n",(0,r.jsx)(e.li,{children:"Robot internal state: Current arm position, gripper status"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Cognition"})," (100-500 ms):"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["Symbolic reasoning: Decompose into sub-goals","\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Navigate to shelf (if not there)"}),"\n",(0,r.jsx)(e.li,{children:"Position arm to reach cup"}),"\n",(0,r.jsx)(e.li,{children:"Grasp cup"}),"\n",(0,r.jsx)(e.li,{children:"Lift and carry cup"}),"\n",(0,r.jsx)(e.li,{children:"Navigate to human"}),"\n",(0,r.jsx)(e.li,{children:"Present cup"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.li,{children:"Path planning: Compute collision-free arm trajectory to cup"}),"\n",(0,r.jsx)(e.li,{children:"Grasp prediction: Predict best grasp for cup shape"}),"\n",(0,r.jsx)(e.li,{children:"Motion planning: Generate smooth joint trajectories"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Action"})," (500+ ms, ongoing):"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Arm motor control: Execute planned trajectory (classical control)"}),"\n",(0,r.jsx)(e.li,{children:"Gripper force control: Grasp cup with appropriate force"}),"\n",(0,r.jsx)(e.li,{children:"Locomotion: Walk to human (if needed)"}),"\n",(0,r.jsx)(e.li,{children:"Recovery: If grasp fails, retry with different grasp point"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Learning"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Store this experience: Successful grasp of red cup"}),"\n",(0,r.jsx)(e.li,{children:"Update grasp model: This cup shape + this approach angle = high success"}),"\n",(0,r.jsx)(e.li,{children:"Update navigation model: Path used was efficient"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Result"}),": Next time robot encounters similar scenario, it executes faster and more reliably."]})]})}function h(n={}){const{wrapper:e}={...(0,l.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>o,x:()=>t});var s=i(6540);const r={},l=s.createContext(r);function o(n){const e=s.useContext(l);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function t(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:o(n.components),s.createElement(l.Provider,{value:e},n.children)}}}]);